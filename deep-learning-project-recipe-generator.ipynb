{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DL.png\" width=\"400px\" height=\"400px\" >  \n",
    "\n",
    "\n",
    "**Team Members:**\n",
    "* Ahad Alsulami \n",
    "* Raneem Alomari\n",
    "* Bedoor Almareni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0M2OGHiBtyMfy6XkEY0b6S",
     "type": "MD"
    }
   },
   "source": [
    "# About üç≤Ô∏è\n",
    "\n",
    "**A recipe generator is a tool or software that uses algorithms to create unique recipes based on specific criteria such as ingredients, dietary restrictions, cooking methods, and cuisine preferences. These generators are designed to help individuals find new and interesting ways to prepare meals and provide inspiration for creating dishes they may not have considered before**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DDCAAnTXGa7aLMn790Sbr4",
     "type": "MD"
    }
   },
   "source": [
    "## Importing  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Rt0t99f14VIEUHhFyxjO8W",
     "report_properties": {
      "rowId": "Ddu94u6qzc0tMocTOV2t4V"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:48:53.330325Z",
     "iopub.status.busy": "2023-06-04T17:48:53.329537Z",
     "iopub.status.idle": "2023-06-04T17:49:03.721040Z",
     "shell.execute_reply": "2023-06-04T17:49:03.719915Z",
     "shell.execute_reply.started": "2023-06-04T17:48:53.330229Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "4a2IEWMpxL69gHBtrycBS3",
     "type": "MD"
    }
   },
   "source": [
    "## **Model configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Gw28g2UgVOsEjuU4ontL2Y",
     "report_properties": {
      "rowId": "UA5cBMlo662l8joHq6zi2D"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:03.724770Z",
     "iopub.status.busy": "2023-06-04T17:49:03.723682Z",
     "iopub.status.idle": "2023-06-04T17:49:03.730225Z",
     "shell.execute_reply": "2023-06-04T17:49:03.728930Z",
     "shell.execute_reply.started": "2023-06-04T17:49:03.724726Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'gpt2'# Name of the pre-trained GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "4TpAVQr6YtElV2DhIuYfCG",
     "report_properties": {
      "rowId": "mwoENNvka6um4ZRoR61rsc"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:03.732790Z",
     "iopub.status.busy": "2023-06-04T17:49:03.732041Z",
     "iopub.status.idle": "2023-06-04T17:49:03.745324Z",
     "shell.execute_reply": "2023-06-04T17:49:03.744272Z",
     "shell.execute_reply.started": "2023-06-04T17:49:03.732754Z"
    }
   },
   "outputs": [],
   "source": [
    "model_save_path = './DLProejectGPT' # Path to save the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "tmohMeDnmYgucw4jMwXOU5",
     "type": "MD"
    }
   },
   "source": [
    "## **Tokenizer initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "dKfCR80HNODcEgVEAFDBYD",
     "report_properties": {
      "rowId": "0e5nDha6BkgattyU6LnSHl"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:03.747658Z",
     "iopub.status.busy": "2023-06-04T17:49:03.746968Z",
     "iopub.status.idle": "2023-06-04T17:49:23.981448Z",
     "shell.execute_reply": "2023-06-04T17:49:23.980247Z",
     "shell.execute_reply.started": "2023-06-04T17:49:03.747621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588d875a0c6e4cb1813ba6004f176068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee1fc1b4a2b4c89bafc75585b75318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1aac70475244409c80295f5b2355a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8045d019f547406dbfabab5c3de757e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d75213a164462f99f3e5d01d300796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name,\n",
    "                                              bos_token='<|startoftext|>',# Beginning of sentence token\n",
    "                                              eos_token='<|endoftext|>',# End of sentence token\n",
    "                                              unk_token='<|unknown|>', # Unknown token\n",
    "                                              pad_token='<|pad|>'# Padding token\n",
    "                                             )\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)# Initialize the GPT2 model\n",
    "model.resize_token_embeddings(len(tokenizer))# Resize the token embeddings to match the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uSmyzA3G8krLGqgYhE6fqa",
     "type": "MD"
    }
   },
   "source": [
    "**GPT2LMHeadModel is a pre-trained language model based on the GPT-2 architecture. It is designed to generate text by predicting the next word in a sequence given the previous words. It is called a \"language model\" because it models the probability distribution of words in a language.\n",
    "The \"LMHead\" in the name stands for \"Language Model Head\", which refers to the fact that the model is trained to predict the next word in a sequence. The \"Head\" part of the name is because this is the final layer of the model, which produces the output. In this specific code, the GPT2LMHeadModel is used to generate recipes by predicting the next word in the recipe based on the previous words.\n",
    "The Trainer is a class provided by the Hugging Face transformers library that is used to train and evaluate models. It provides an easy-to-use interface for training and fine-tuning models, including handling data loading, batching, and optimization.In this code, the Trainer is used to fine-tune the GPT2LMHeadModel on a custom recipe dataset. It takes care of training the model for a specified number of epochs, handling the batching of data, and applying the specified optimizer and learning rate scheduler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "nAPyOlNeriLsBWTLs5lP5c",
     "report_properties": {
      "rowId": "eXKKZ3xa70ZakHgxyWHvpU"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:23.985454Z",
     "iopub.status.busy": "2023-06-04T17:49:23.985063Z",
     "iopub.status.idle": "2023-06-04T17:49:24.125018Z",
     "shell.execute_reply": "2023-06-04T17:49:24.124039Z",
     "shell.execute_reply.started": "2023-06-04T17:49:23.985415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./DLProejectGPT/tokenizer_config.json',\n",
       " './DLProejectGPT/special_tokens_map.json',\n",
       " './DLProejectGPT/vocab.json',\n",
       " './DLProejectGPT/merges.txt',\n",
       " './DLProejectGPT/added_tokens.json',\n",
       " './DLProejectGPT/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_save_path)# Save the tokenizer to the specified model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "4c9FRjKZnKjpo2AjCmx8i1",
     "report_properties": {
      "rowId": "CErXK2yFPUKZP3GVpB2fjG"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:24.127055Z",
     "iopub.status.busy": "2023-06-04T17:49:24.126456Z",
     "iopub.status.idle": "2023-06-04T17:49:25.911643Z",
     "shell.execute_reply": "2023-06-04T17:49:25.910623Z",
     "shell.execute_reply.started": "2023-06-04T17:49:24.127015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50259]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<|pad|>'])# Convert the empty token to its corresponding token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "yQOmEQq5LQ2dFfYz3iXV9u",
     "type": "MD"
    }
   },
   "source": [
    "**This generate function takes a prompt as input, encodes it using the tokenizer, generates output text based on the prompt using the model, and finally decodes and prints the generated text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "8BC5pRp1jxjR0cUEek45Uc",
     "report_properties": {
      "rowId": "gJfhcggvZJMXpoq8dVa7nG"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:25.914519Z",
     "iopub.status.busy": "2023-06-04T17:49:25.913716Z",
     "iopub.status.idle": "2023-06-04T17:49:25.922504Z",
     "shell.execute_reply": "2023-06-04T17:49:25.921469Z",
     "shell.execute_reply.started": "2023-06-04T17:49:25.914478Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "    # Encode the prompt using the tokenizer\n",
    "    inputs = tokenizer.encode_plus(prompt, return_tensors='pt')\n",
    "    # Generate output text based on the prompt using the model\n",
    "    output = model.generate(**inputs,max_length=256,do_sample=True,pad_token_id=50259)\n",
    "    # Decode and print the generated text\n",
    "    print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Hpx7W2fGKYcSW9SNB3AQbH",
     "report_properties": {
      "rowId": "9WQc0pdI3a2ISJIvj7WaSe"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:25.925120Z",
     "iopub.status.busy": "2023-06-04T17:49:25.924267Z",
     "iopub.status.idle": "2023-06-04T17:49:25.935727Z",
     "shell.execute_reply": "2023-06-04T17:49:25.934648Z",
     "shell.execute_reply.started": "2023-06-04T17:49:25.925079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|startoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|unknown|>',\n",
       " 'pad_token': '<|pad|>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the special tokens map from the tokenizer\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "si2hOB35r5Vu85YucgYCIx",
     "report_properties": {
      "rowId": "gt0jp8cQL8rXtxqw6bTi7p"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:25.938254Z",
     "iopub.status.busy": "2023-06-04T17:49:25.937504Z",
     "iopub.status.idle": "2023-06-04T17:49:25.947341Z",
     "shell.execute_reply": "2023-06-04T17:49:25.946232Z",
     "shell.execute_reply.started": "2023-06-04T17:49:25.938215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50257]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<|startoftext|>'],)# Convert the empty token to its corresponding token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "M7HsbnsRDKwFSXl3a5UW3e",
     "type": "MD"
    }
   },
   "source": [
    "## **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "0s8H37ECP8ErbIXyNstLj7",
     "report_properties": {
      "rowId": "TFJs9rPdjEhQtOjSJZkrJ8"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:25.949771Z",
     "iopub.status.busy": "2023-06-04T17:49:25.948988Z",
     "iopub.status.idle": "2023-06-04T17:49:26.234274Z",
     "shell.execute_reply": "2023-06-04T17:49:26.233183Z",
     "shell.execute_reply.started": "2023-06-04T17:49:25.949735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame called 'clean'\n",
    "clean = pd.read_csv('/kaggle/input/food-dataset/Food_Recipe_Dataset.csv')\n",
    "# Shuffle the rows of the DataFrame\n",
    "clean = clean.sample(frac=1)\n",
    "# Reset the index of the DataFrame\n",
    "clean.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "MiV11DM8ADEZuqFz896ZFK",
     "report_properties": {
      "rowId": "GdCRIGhPC9yUQvSOW2paB6"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.236479Z",
     "iopub.status.busy": "2023-06-04T17:49:26.236061Z",
     "iopub.status.idle": "2023-06-04T17:49:26.251364Z",
     "shell.execute_reply": "2023-06-04T17:49:26.250100Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.236439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sindhi' 'Mexican' 'Indian' 'Tamil Nadu' 'Chettinad' 'Goan Recipes'\n",
      " 'North Indian Recipes' 'Karnataka' 'Chinese' 'Continental' 'Rajasthani'\n",
      " 'Maharashtrian Recipes' 'South Indian Recipes' 'Italian Recipes' 'Udupi'\n",
      " 'Asian' 'Indo Chinese' 'Bengali Recipes' 'Kerala Recipes' 'Parsi Recipes'\n",
      " 'French' 'Awadhi' 'European' 'Coorg' 'Assamese' 'Punjabi' 'Kashmiri'\n",
      " 'Gujarati Recipes\\ufeff' 'Andhra' 'Coastal Karnataka' 'Thai'\n",
      " 'Mediterranean' 'Konkan' 'Japanese' 'Sri Lankan' 'Fusion'\n",
      " 'South Karnataka' 'Sichuan' 'Himachal' 'Middle Eastern' 'Caribbean'\n",
      " 'Uttar Pradesh' 'African' 'Jharkhand' 'Nepalese' 'Malabar' 'Mangalorean'\n",
      " 'Lucknowi' 'Oriya Recipes' 'Vietnamese' 'Mughlai' 'Pakistani'\n",
      " 'Hyderabadi' 'North Karnataka' 'North East India Recipes' 'Hunan'\n",
      " 'Malvani' 'Nagaland' 'Malaysian' 'Shandong' 'British' 'Cantonese' 'Greek'\n",
      " 'Indonesian' 'Bihari' 'Afghan' 'Kongunadu' 'Haryana' 'Lunch' 'Brunch'\n",
      " 'American' 'Korean' 'Arab' 'Uttarakhand-North Kumaon' 'World Breakfast'\n",
      " 'Dinner' 'Side Dish' 'Appetizer' 'Snack' 'Dessert' 'Burmese' 'Jewish']\n"
     ]
    }
   ],
   "source": [
    "print(clean['Cuisine'].unique())#unique cuisine found in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "JSa2QSNCspdRP5SFgTJzD2",
     "report_properties": {
      "rowId": "PK7tYyUPIqM9m5y00CqQn8"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.254506Z",
     "iopub.status.busy": "2023-06-04T17:49:26.253270Z",
     "iopub.status.idle": "2023-06-04T17:49:26.260488Z",
     "shell.execute_reply": "2023-06-04T17:49:26.259207Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.254466Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_recipe(idx):\n",
    "    # Print the ingredients and instructions of the recipe at the specified index.\n",
    "    print(f\"{clean['ingredients'][idx]}\\n\\n{clean['instructions'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "3tjYavlVB0vwzMXfk0HLv6",
     "type": "MD"
    }
   },
   "source": [
    "**the form_string function that takes an ingredient and an instruction as inputs and returns a formatted string combining them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Bo9cFGWDSrgwojp6haq42u",
     "report_properties": {
      "rowId": "uia0dwjWoYfHu12hiTqQ3i"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.262880Z",
     "iopub.status.busy": "2023-06-04T17:49:26.261981Z",
     "iopub.status.idle": "2023-06-04T17:49:26.270366Z",
     "shell.execute_reply": "2023-06-04T17:49:26.269228Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.262833Z"
    }
   },
   "outputs": [],
   "source": [
    "def form_string(ingredient,instruction):\n",
    "    # Formulate the string combining the ingredients and instructions\n",
    "    s = f\"<|startoftext|>Ingredients:\\n{ingredient.strip()}\\n\\nInstructions:\\n{instruction.strip()}<|endoftext|>\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "OVlWECAz2VwuW12BUR1xN7",
     "report_properties": {
      "rowId": "2dFxZsU0RcsYES7OG6gYin"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.276391Z",
     "iopub.status.busy": "2023-06-04T17:49:26.276077Z",
     "iopub.status.idle": "2023-06-04T17:49:26.406972Z",
     "shell.execute_reply": "2023-06-04T17:49:26.405961Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.276363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the form_string function to each row in the clean DataFrame\n",
    "# using 'TranslatedIngredients' and 'TranslatedInstructions' columns as inputs\n",
    "data = clean.apply(lambda x:form_string(x['TranslatedIngredients'],x['TranslatedInstructions']),axis=1).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "G4AipDPe16LXpBAtJRqEdX",
     "report_properties": {
      "rowId": "r4QuqTNHfMCSqDX5dvneeL"
     },
     "type": "MD"
    }
   },
   "source": [
    "https://towardsdatascience.com/guide-to-fine-tuning-text-generation-models-gpt-2-gpt-neo-and-t5-dc5de6b3bc5e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "NXW8ZGxhh8G94J1WVC5QDY",
     "type": "MD"
    }
   },
   "source": [
    "## **splits the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Zx9QHYJ09T811FHzQzM0A2",
     "report_properties": {
      "rowId": "mAlaxpQC3a1A8rVYVx0Cvq"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.409133Z",
     "iopub.status.busy": "2023-06-04T17:49:26.408554Z",
     "iopub.status.idle": "2023-06-04T17:49:26.415065Z",
     "shell.execute_reply": "2023-06-04T17:49:26.413964Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.409092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the proportion of data to be used for training\n",
    "train_size = 0.85\n",
    "# Calculate the length of the training set based on the specified train_size\n",
    "train_len = int(train_size * len(data))\n",
    "# Split the data into training and validation sets\n",
    "train_data = data[:train_len]# Contains the first train_len elements for training\n",
    "val_data = data[train_len:] # Contains the remaining elements for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0LMJufRJqHbOr2hUIwgywa",
     "type": "MD"
    }
   },
   "source": [
    "**Defines a RecipeDataset class, which is a PyTorch dataset for working with recipe data. It takes a data list as input during initialization.**\n",
    "\n",
    "**The RecipeDataset class has three main methods:**\n",
    "\n",
    "1 - Initializes the dataset by processing the data list. It tokenizes and encodes each item in the data list using the tokenizer. The resulting input_ids and attention_masks are stored in separate lists self.input_ids and self.attn_masks.**\n",
    "\n",
    "2 - Returns the total number of items in the dataset, which is the length of the data list.\n",
    "\n",
    "3 - Returns the input_ids and attention_masks for the item at the given index idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "1ps3GeWplJLJaes9eGpjld",
     "report_properties": {
      "rowId": "lANwUfnsjpRhJe2HfQKJiz"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.417364Z",
     "iopub.status.busy": "2023-06-04T17:49:26.416717Z",
     "iopub.status.idle": "2023-06-04T17:49:26.428370Z",
     "shell.execute_reply": "2023-06-04T17:49:26.427288Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.417324Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecipeDataset:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        # Iterate over the data and process each item\n",
    "        for item in tqdm(data):\n",
    "            # Tokenize and encode the item using the tokenizer\n",
    "            encodings = tokenizer.encode_plus(item,\n",
    "                                              truncation=True,\n",
    "                                              padding='max_length',\n",
    "                                              max_length=1024,\n",
    "                                              return_tensors='pt'\n",
    "                                             )\n",
    "            # Extract and store the input_ids and attention_masks\n",
    "            self.input_ids.append(torch.squeeze(encodings['input_ids'],0))\n",
    "            self.attn_masks.append(torch.squeeze(encodings['attention_mask'],0))\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the total number of items in the dataset\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # Return the input_ids and attention_masks for the item at the given index\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "l0rKvNSkAMTK8vQeWWi3U2",
     "type": "MD"
    }
   },
   "source": [
    "**collate_fn function collate a batch of data samples in the custom RecipeDataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "HGnUeweCYmVMeVEE63do6H",
     "report_properties": {
      "rowId": "eCCLnfRmbtcC4UAr1mGoAB"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.431802Z",
     "iopub.status.busy": "2023-06-04T17:49:26.431345Z",
     "iopub.status.idle": "2023-06-04T17:49:26.443661Z",
     "shell.execute_reply": "2023-06-04T17:49:26.442615Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.431765Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Stack the input_ids, attention_mask, and labels tensors in the batch\n",
    "    return {\n",
    "        'input_ids': torch.stack([item[0] for item in batch]),\n",
    "        'attention_mask': torch.stack([item[1] for item in batch]),\n",
    "        'labels': torch.stack([item[0] for item in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "0EqTkPFyiRJFcjKlI4Osml",
     "report_properties": {
      "rowId": "ZacWPRPonxY4DecLiVPBqD"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:26.446592Z",
     "iopub.status.busy": "2023-06-04T17:49:26.445842Z",
     "iopub.status.idle": "2023-06-04T17:49:35.959667Z",
     "shell.execute_reply": "2023-06-04T17:49:35.958640Z",
     "shell.execute_reply.started": "2023-06-04T17:49:26.446538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee036ef9115f4a4da1ee30c9c4d062df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85361355e0644a66a526c7b84fc9a4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/891 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize train_ds with the training data\n",
    "train_ds = RecipeDataset(train_data)\n",
    "# Initialize val_ds with the validation data\n",
    "val_ds = RecipeDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "8qVuuIRmBqNJNAXvmV6Ygz",
     "report_properties": {
      "rowId": "Clbywyj8TYmhDKKnYzUeBl"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:35.962605Z",
     "iopub.status.busy": "2023-06-04T17:49:35.961404Z",
     "iopub.status.idle": "2023-06-04T17:49:36.073842Z",
     "shell.execute_reply": "2023-06-04T17:49:36.072746Z",
     "shell.execute_reply.started": "2023-06-04T17:49:35.962559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize args with the training arguments and settings\n",
    "args = TrainingArguments(\n",
    "    output_dir=model_save_path,  # Directory to save the trained model\n",
    "    per_device_train_batch_size=2,  # Batch size for training on each device\n",
    "    per_device_eval_batch_size=2,  # Batch size for evaluation on each device\n",
    "    gradient_accumulation_steps=2,  # Number of steps to accumulate gradients before performing optimization\n",
    "    report_to='none',  # Disable reporting of training progress\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "    save_strategy='no'  # Disable saving of checkpoints during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "me4BB8wpXJ5x6VDgLMh9qA",
     "report_properties": {
      "rowId": "bONIL9KJ0AZNBqP3UbnwKN"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:36.075627Z",
     "iopub.status.busy": "2023-06-04T17:49:36.075238Z",
     "iopub.status.idle": "2023-06-04T17:49:36.084615Z",
     "shell.execute_reply": "2023-06-04T17:49:36.083378Z",
     "shell.execute_reply.started": "2023-06-04T17:49:36.075590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the optimizer using the AdamW algorithm\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# Initialize the scheduler using the CosineAnnealingWarmRestarts method\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, 20, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "c0veGgKZQRpOiPTSUJ18SC",
     "report_properties": {
      "rowId": "6ApWhjBj1HZyZ4ouxPloYp"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:36.086814Z",
     "iopub.status.busy": "2023-06-04T17:49:36.086191Z",
     "iopub.status.idle": "2023-06-04T17:49:41.635498Z",
     "shell.execute_reply": "2023-06-04T17:49:41.634421Z",
     "shell.execute_reply.started": "2023-06-04T17:49:36.086775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the trainer object for model training\n",
    "trainer = Trainer(\n",
    "    model,  # The model to be trained\n",
    "    args,  # The training arguments and settings\n",
    "    train_dataset=train_ds,  # The training dataset\n",
    "    eval_dataset=val_ds,  # The validation dataset\n",
    "    data_collator=collate_fn,  # The collate function for batching the data\n",
    "    optimizers=(optim, scheduler)  # The optimizer and scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "sl23zKRmctgYMUya6FZc4B",
     "report_properties": {
      "rowId": "5ulOhjA5i9UoecXvi2Bjy3"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T17:49:41.637808Z",
     "iopub.status.busy": "2023-06-04T17:49:41.637025Z",
     "iopub.status.idle": "2023-06-04T18:41:48.568763Z",
     "shell.execute_reply": "2023-06-04T18:41:48.567632Z",
     "shell.execute_reply.started": "2023-06-04T17:49:41.637768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 5047\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1893\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1893' max='1893' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1893/1893 51:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1893, training_loss=0.8481587340953926, metrics={'train_runtime': 3126.9099, 'train_samples_per_second': 4.842, 'train_steps_per_second': 0.605, 'total_flos': 7912445313024000.0, 'train_loss': 0.8481587340953926, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()#starts the training process using the trainer object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "FWnUq5jQCqwsyz2yYQUu7G",
     "report_properties": {
      "rowId": "mds9oDU6Imo0IjhH8M6PSD"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:41:48.571414Z",
     "iopub.status.busy": "2023-06-04T18:41:48.570409Z",
     "iopub.status.idle": "2023-06-04T18:41:49.632405Z",
     "shell.execute_reply": "2023-06-04T18:41:49.631369Z",
     "shell.execute_reply.started": "2023-06-04T18:41:48.571372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./DLProejectGPT\n",
      "Configuration saved in ./DLProejectGPT/config.json\n",
      "Model weights saved in ./DLProejectGPT/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()#to save the trained model after the training process is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "2fxQzIEegt0THyC0JBVPjJ",
     "report_properties": {
      "rowId": "yI6HCY6nfsrlB3SszNiJVC"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:41:49.639273Z",
     "iopub.status.busy": "2023-06-04T18:41:49.636928Z",
     "iopub.status.idle": "2023-06-04T18:41:52.231128Z",
     "shell.execute_reply": "2023-06-04T18:41:52.230131Z",
     "shell.execute_reply.started": "2023-06-04T18:41:49.639236Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "rNRDH1h2zl3lBkzVF9qHnD",
     "report_properties": {
      "rowId": "0UWn53n7EfzvVJRhco5sIu"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:41:52.233217Z",
     "iopub.status.busy": "2023-06-04T18:41:52.232530Z",
     "iopub.status.idle": "2023-06-04T18:41:54.725203Z",
     "shell.execute_reply": "2023-06-04T18:41:54.723860Z",
     "shell.execute_reply.started": "2023-06-04T18:41:52.233176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/working/DLProejectGPT/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"/kaggle/working/DLProejectGPT\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50260\n",
      "}\n",
      "\n",
      "loading configuration file /kaggle/working/DLProejectGPT/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"/kaggle/working/DLProejectGPT\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50260\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/working/DLProejectGPT/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /kaggle/working/DLProejectGPT.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading file /kaggle/working/DLProejectGPT/vocab.json\n",
      "loading file /kaggle/working/DLProejectGPT/merges.txt\n",
      "loading file /kaggle/working/DLProejectGPT/tokenizer.json\n",
      "loading file /kaggle/working/DLProejectGPT/added_tokens.json\n",
      "loading file /kaggle/working/DLProejectGPT/special_tokens_map.json\n",
      "loading file /kaggle/working/DLProejectGPT/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "pl = pipeline(task='text-generation',model='/kaggle/working/DLProejectGPT')#initializes a text generation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "FF0UhznC7N6of5yfJMQgKQ",
     "type": "MD"
    }
   },
   "source": [
    "**The create_prompt function takes a string of ingredients and a cuisine name as input and creates a formatted prompt string for generating a recipe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "bpjew3G5MeTh80cRt7BM7r",
     "report_properties": {
      "rowId": "Urkx8cHztgJEeXfDUK2eSW"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:41:54.728058Z",
     "iopub.status.busy": "2023-06-04T18:41:54.727666Z",
     "iopub.status.idle": "2023-06-04T18:41:54.742311Z",
     "shell.execute_reply": "2023-06-04T18:41:54.739752Z",
     "shell.execute_reply.started": "2023-06-04T18:41:54.728013Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_prompt(cuisine,ingredients):\n",
    "    # Convert the ingredients to lowercase and remove leading/trailing whitespaces\n",
    "    ingredients = ','.join([x.strip().lower() for x in ingredients.split(',')])\n",
    "    # Replace commas with newline characters for better ingredient formatting\n",
    "    ingredients = ingredients.strip().replace(',', '\\n')\n",
    "    # Create the prompt string with the formatted ingredients and cuisine \n",
    "    s = f\"\\n\\nCuisine:\\n{Cuisine.value}\\n\\nIngredients:\\n{ingredients}\\n\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "zDoPMfLJx7rMb3rQcYVzyv",
     "report_properties": {
      "rowId": "31P9LK5YXIOPotImsWAuZX"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:41:54.744816Z",
     "iopub.status.busy": "2023-06-04T18:41:54.744169Z",
     "iopub.status.idle": "2023-06-04T18:45:11.016512Z",
     "shell.execute_reply": "2023-06-04T18:45:11.015443Z",
     "shell.execute_reply.started": "2023-06-04T18:41:54.744776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Want to explore new flavors? Choose your cuisine preference!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495e763e796c48caa4f573a563b68d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('Sindhi', 'Mexican', 'Indian', 'Tamil Nadu', 'Chettinad', 'Goan Recipes', 'North Indian Reci‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Add your ingredients for a unique recipe!\n",
      "(separate them with a comma :)\n",
      " flour,sugar,cinnamon,vanilla\n"
     ]
    }
   ],
   "source": [
    "# Cusinie Selection\n",
    "print(\"Want to explore new flavors? Choose your cuisine preference!\\n\")\n",
    "Cuisine = widgets.Dropdown(options = clean['Cuisine'].unique(),\n",
    "                                value=None)\n",
    "display(Cuisine)\n",
    "\n",
    "\n",
    "# Ingredients Selection\n",
    "ingredients = [i for i in input(\"\\nAdd your ingredients for a unique recipe!\"+\n",
    "                                \"\\n(separate them with a comma :)\\n\").split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "18Fe7YXlxaquFRFyrLrQMC",
     "report_properties": {
      "rowId": "sFypHgKS21tXn9j5ptAC6h"
     },
     "type": "CODE"
    },
    "execution": {
     "iopub.execute_input": "2023-06-04T18:45:35.204251Z",
     "iopub.status.busy": "2023-06-04T18:45:35.203856Z",
     "iopub.status.idle": "2023-06-04T18:45:47.775010Z",
     "shell.execute_reply": "2023-06-04T18:45:47.773860Z",
     "shell.execute_reply.started": "2023-06-04T18:45:35.204218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cuisine:\n",
      "Arab\n",
      "\n",
      "Ingredients:\n",
      "flour\n",
      "sugar\n",
      "cinnamon\n",
      "vanilla\n",
      "\n",
      "1 cup raita flour, salt\n",
      "\n",
      "1 cup rice flour, 1/2 cup water, salt - as required\n",
      "\n",
      "pinch cinnamon, 1/2 cup sugar, 2 cups water, 1/2 teaspoon turmeric powder\n",
      "\n",
      "Instructions:\n",
      "To make the raita rice dough, firstly we will first make the raita.\n",
      "In a mixer, add the rice flour, salt, turmeric powder, cinnamon, sugar, water and grind to a smooth dough.\n",
      "Keep it aside.Now heat oil in a pan.\n",
      "Add cinnamon, sugar, turmeric and cook for 2 minutes.\n",
      "Once the spices start to sizzle, add the raita flour, rice flour, water and cook for 2 minutes.\n",
      "Add the remaining water and cook until the raita is cooked well.\n",
      "After 2 minutes, add the raita dough into the mixer and mix well.\n",
      "Check the salt and spice levels and adjust according to your taste.\n",
      "Serve the raita rice along with steamed rice and phulkas for a weekday meal.\n",
      "You can also serve it with phulkas for a wholesome lunch.\n"
     ]
    }
   ],
   "source": [
    "for ing in ingredients:\n",
    "    # Create a prompt using the current ingredient set and the specified cuisine\n",
    "    prompt = create_prompt(Cuisine.value,ing)\n",
    "    # Generate a recipe using the pipeline with specified parameters and print the generated recipe\n",
    "    print(pl(prompt,\n",
    "         max_new_tokens=512,\n",
    "         penalty_alpha=0.6,\n",
    "         top_k=4,\n",
    "         pad_token_id=50259\n",
    "        )[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
